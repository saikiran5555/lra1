{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489dad14",
   "metadata": {},
   "source": [
    "The ROC (Receiver Operating Characteristic) curve is a graphical representation used to evaluate the performance of a binary classifier, such as a logistic regression model. It is particularly useful for understanding how well the model distinguishes between two classes under various threshold settings.\n",
    "\n",
    "Understanding the ROC Curve:\n",
    "True Positive Rate (TPR) and False Positive Rate (FPR):\n",
    "\n",
    "The ROC curve plots the True Positive Rate (TPR, also known as Sensitivity or Recall) against the False Positive Rate (FPR) at various threshold settings.\n",
    "TPR is calculated as \n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "TPR= \n",
    "TP+FN\n",
    "TP\n",
    "​\n",
    " , where TP is the number of true positives and FN is the number of false negatives.\n",
    "FPR is calculated as \n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "FPR= \n",
    "FP+TN\n",
    "FP\n",
    "​\n",
    " , where FP is the number of false positives and TN is the number of true negatives.\n",
    "Thresholds:\n",
    "\n",
    "The threshold is the probability or score at which the model classifies an instance as positive. By varying this threshold, the TPR and FPR change, thus altering the model's sensitivity to classifying positive instances.\n",
    "Constructing the ROC Curve:\n",
    "Varying the Threshold:\n",
    "\n",
    "For a logistic regression model, predictions are probabilities. By varying the threshold from 0 to 1, different TPR and FPR values are obtained.\n",
    "Plotting TPR vs. FPR:\n",
    "\n",
    "These pairs of TPR and FPR values are plotted on a graph, with FPR on the X-axis and TPR on the Y-axis.\n",
    "Using the ROC Curve in Evaluation:\n",
    "Area Under the Curve (AUC):\n",
    "\n",
    "The Area Under the ROC Curve (AUC) is a single number summary of the model performance. An AUC of 1 represents a perfect classifier, while an AUC of 0.5 represents a model with no discriminative power, equivalent to random guessing.\n",
    "Interpreting the Curve:\n",
    "\n",
    "A model whose ROC curve is closer to the top left corner performs better in distinguishing between the positive and negative classes.\n",
    "The curve can also help in selecting an optimal threshold that balances TPR and FPR, depending on the specific requirements of the application (e.g., prioritizing minimizing false positives or maximizing true positives).\n",
    "Advantages of the ROC Curve:\n",
    "Performance at Various Thresholds:\n",
    "\n",
    "It shows the trade-off between sensitivity and specificity (1 - FPR) for different thresholds without needing to actually change the threshold.\n",
    "Insensitive to Class Distribution:\n",
    "\n",
    "The ROC curve is effective even if the classes are highly imbalanced.\n",
    "Comparative Tool:\n",
    "\n",
    "Allows comparison between multiple models. A model with a ROC curve that dominates another (higher and to the left) is considered better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
